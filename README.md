# llm-testbench
This project aims to compare different LLM models on their ability to generate code and unit tests for prompts from the HumanEval dataset.
